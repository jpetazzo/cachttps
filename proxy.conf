proxy_cache_path /cache levels=1:2 keys_zone=my_cache:1m max_size=10g inactive=1y use_temp_path=off;

server {
  listen 3131;
  listen [::]:3131;

  # GitHub has *huge* content-security-policy headers.
  # It looks like we need to bump up these buffers,
  # otherwise we get the following error:
  # upstream sent too big header while reading response header from upstream
  proxy_buffer_size 16k;
  proxy_buffers 4 16k;
  proxy_busy_buffers_size 32k;

  proxy_cache my_cache;
  # This means, "if multiple clients send the same
  # request at the same time, make only one request
  # to upstream".
  proxy_cache_lock on;

  # If upstream is down or misbehaving, serve stale content.
  proxy_cache_use_stale error timeout http_404 http_500 http_503 http_504;

  # It looks like this is necessary, otherwise nothing gets cached...?
  proxy_cache_valid 200 1y;

  # Let's drop all these headers (our clients will be curl anyway...)
  proxy_hide_header cache-control;
  proxy_hide_header set-cookie;
  proxy_hide_header vary;
  proxy_hide_header content-security-policy;

  # When you download releases from GitHub (e.g. tarballs etc.),
  # GitHub sets cookies, has a "cache-control: no-cache" header,
  # and a "vary:" header. Let's drop that nonsense.
  proxy_ignore_headers cache-control set-cookie vary;

  # Add a little debugging header to tell us if it was a HIT or MISS.
  add_header x-cachttps-status $upstream_cache_status;

  # By default, NGINX "compresses" URL (and the double-slash causes problems).
  merge_slashes off;
  location /https://github.com/ {
    proxy_pass https://github.com/;
  }

  # Handle redirections internally.
  error_page 302 = @redirect;
  proxy_intercept_errors on;
  # This one is to handle multiple levels of redirects.
  recursive_error_pages on;

  location @redirect {
    set $the_location '$upstream_http_location';
    resolver 1.1.1.1;
    proxy_pass $the_location;
  }

  # Fallback route to 400 every other request.
  location / {
    return 400;
  }
}
